\documentclass[a4paper,12pt]{article} % This defines the style of your paper

\usepackage[top = 2.5cm, bottom = 2.5cm, left = 2.5cm, right = 2.5cm]{geometry} 
\usepackage[utf8]{inputenc} %utf8 % lettere accentate da tastiera
\usepackage[english]{babel} % lingua del documento
\usepackage[T1]{fontenc} % codifica dei font

\usepackage{multirow} % Multirow is for tables with multiple rows within one 
%cell.
\usepackage{booktabs} % For even nicer tables.

\usepackage{graphicx} 

\usepackage{setspace}
\setlength{\parindent}{0in}

\usepackage{float}

\usepackage{fancyhdr}

\usepackage{caption}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{color}

\usepackage[hidelinks]{hyperref}
\usepackage{csquotes}
\usepackage{subfigure}

\pagestyle{fancy}

\setlength\parindent{24pt}

\fancyhf{}

\lhead{\footnotesize Deep Learning Lab: Assignment 2}

\rhead{\footnotesize Giorgia Adorni}

\cfoot{\footnotesize \thepage} 

\begin{document}
	

	\thispagestyle{empty}  
	\noindent{
	\begin{tabular}{p{15cm}} 
		{\large \bf Deep Learning Lab} \\
		Universit√† della Svizzera Italiana \\ Faculty of Informatics \\ \today  \\
		\hline
		\\
	\end{tabular} 
	
	\vspace*{0.3cm} 
	
	\begin{center}
		{\Large \bf Assignment 2: Convolutional Neural Network}
		\vspace{2mm}
		
		{\bf Giorgia Adorni (giorgia.adorni@usi.ch)}
		
	\end{center}  
}
	\vspace{0.4cm}

	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\section{Introduction}
	The scope of this project is to implement a convolutional neural network to 
	classify the images in the CIFAR-10 dataset.
	
	First of all, the original training set has been shuffled and divided into 
	train and validation sets, with $49000$ and $1000$ images respectively. A 
	seed has been used to reproduce the same sample split and use them in the 
	different models. Instead, the test set provided contains $10000$ images.
	
	A certain preprocessing has been applied to the data. The pixel values of 
	each sample, initially comprised between 0 and 255, have been rescaled 
	between 0 and 1. To represent the class assignments, which were integers 
	between 0 and 9, three binary assignment matrices have been created, one 
	for each set of data. 
	
	The architecture of the convolutional neural network follow the 
	instructions provided, as well as the hyper-parameter values for the models 
	presented in the Sections \ref{section:model0} and \ref{section:dropout}.
	In the training phase, mini-batches were used. In particular, each 
	epoch splits the training set in different samples of data.
	
	All the models were implemented using \texttt{TensorFlow} and trained on a 
	NVIDIA Tesla V100-PCIE-16GB GPU.
	
	%FIXME
	Note: Since mini-batches are used during the training of the models, the 
	loss and the accuracy of all samples is averaged, obtaining a less noisy 
	estimate.
	
	\section{Performance of the initial model}
	\label{section:model0}
	In Table \ref{tab:model0} is summarised the architecture of the network 
	used in the first experiment.	
	
	\begin{figure}[H]
		\centering
		
		\begin{tabular}{cccccccc}
		\toprule
		\textbf{conv1} & \textbf{conv2} & \textbf{mpool1} & \textbf{conv3} &
		\textbf{conv4} & \textbf{mpool1} &   \textbf{fc} &
		\textbf{softmax} \\
		\midrule
		3$\times$3,  32 & 3$\times$3, 32 & 2$\times$2 &3$\times$3, 64 & 
		3$\times$3, 64  & 2$\times$2  & 512 & 10\\
		s. 2$\times$2 &   s. 2$\times$2 &   s. 1$\times$1 & s. 1$\times$1  & s. 
		2$\times$2 & s. 2$\times$2 && \\
		p. same & p. same & p. same  & p. same & p. same & p. same &&\\
		\bottomrule
		\end{tabular}
		\captionof{table}{Network architecture}
		\label{tab:model0}
	\end{figure}
	
	The model is trained for $50$ epochs and \texttt{Adam} is used as 
	optimiser with learning rate $0,001$.
	As loss function, the Softmax Cross Entropy with Logits is used since the 
	model is a multi-class classifier. Moreover, once per epoch, is documented 
	the classification accuracy on both the train and validation set.
	The performance are shown in Figure \ref{fig:model0-performance}.
	
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/1-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/1-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on the initial model}
		\label{fig:model0-performance}
	\end{figure}
	
	As can be seen in Figure (a), the train accuracy rapidly grows up to 
	$100\%$, while the validation accuracy remains stable at $70\%$.  
	The final accuracy on the valid set is $70.30\%$.
	For what concerns the loss, it is clear that the model overfits the data. 
	In fact, the train loss is close to $0$ while the validation one 
	diverges.
	
	\begin{table}[H]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cc|cc|c}
			\toprule
			& \multicolumn{2}{c}{\textbf{Accuracy}} & 
			\multicolumn{2}{c}{\textbf{Loss}} & \multirow{2}*{\textbf{Train 
					Time}} \\
			& Train & Validation
			& Train & Validation	& 						 		\\
			\midrule
			\textbf{Model 1} & 98.99\% & 70.30\%  & 0.05 & 4.20 & 406 sec \\
			
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model performances}
		\label{tab:performace-m1}
	\end{table}

	For this reason, in Section \ref{section:dropout} is presented a new model 
	that has the aim of improving this results.
	
	\section{Regularisation of the model with dropout}
	\label{section:dropout}
	The model proposed in this section involve the use of a model 
	regularisation technique, that is the addition of a dropout layer after 
	each max-pooling and fully-connected layer. In particular, during the 
	training phase, the probability to keep each neuron is setted to $0.5$, 
	while in the validation set should be $1$.	
	
	The architecture of the new network is presented in Table \ref{tab:model1}.	
	
	\begin{figure}[H]
		\centering
		
		\begin{tabular}{cccccccc}
			\toprule
			\textbf{conv1} & \textbf{conv2} & \textbf{mpool1} & 
			\textbf{conv3} &
			\textbf{conv4} & \textbf{mpool2} &   \textbf{fc} &
			\textbf{softmax} \\
			\midrule
			3$\times$3,  32 & 3$\times$3, 32 & 2$\times$2 &3$\times$3, 64 & 
			3$\times$3, 64  & 2$\times$2  & 512 & 10\\
			s. 2$\times$2 &   s. 2$\times$2 &   s. 1$\times$1 & s. 1$\times$1  
			& s. 
			2$\times$2 & s. 2$\times$2 && \\
			p. same & p. same & p. same  & p. same & p. same & p. same &&\\
			 &  & dropout  &  &  & dropout & dropout & \\
			\bottomrule
		\end{tabular}
		\captionof{table}{Network architecture}
		\label{tab:model1}
	\end{figure}

	The actual performance are shown in Figure \ref{fig:model1-performance}.
	as can be legitimately expected after the application of the dropout. 

	Even if the performance on the training worsen respect to the previous 
	model, due to the regularisation that is applied only on this set, the 
	performance on the validation increased of $9.90\%$.
	
	In this experiment, the validation accuracy is $80.20\%$, significantly 
	better compared to the previous model.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/2-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/2-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on the regularised model}
		\label{fig:model1-performance}
	\end{figure}
	
	Instead, observing the loss curves, after the $30\mathrm{th}$ epochs it is 
	possible to see some signs of overfitting. In this case, both the curves 
	has low values. 
	
	\begin{table}[htb]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cc|cc|c}
			\toprule
			& \multicolumn{2}{c}{\textbf{Accuracy}} & 
			\multicolumn{2}{c}{\textbf{Loss}} & \multirow{2}*{\textbf{Train 
					Time}} \\
			& Train & Validation & Train & Validation & \\
			\midrule
			\textbf{Model 2} & 79.32\% & 80.20\%  & 0.60 & 0.61 & 415 sec \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model performances}
		\label{tab:performace-m2}
	\end{table}

	In the following section will be attempted some additional experiments by 
	modifying the model's hyperparameters.
	  
	\section{Hyperparameter settings}
	\label{section:hyperparam}
	
	In this section will be discussed $7$ different configuration for the 
	hyperparameters of the network, with the aim of improving the validation 
	accuracy. In particular, will be documented the performances according to 
	the modification of the following hyperparameters: learning rate, 
	mini-batch size, dropout and number of epochs. In this analysis, only the 
	models with the best performances will be included. In Table 
	\ref{tab:param1} are documented the different hyperparameter settings of 
	these. 
	
	\begin{table}[htb]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cccc}
			\toprule
			& \textbf{learning rate} & \textbf{batch size} & \textbf{dropout} & 
			\textbf{epochs} \\
			\midrule
			\textbf{Model 1}  & {1e-3} & {32}  &  -  & 50\\
			\textbf{Model 2}  & {1e-3} & {32}  & 0.5 & 50\\
			\textbf{Model 3}  & {1e-4} & {32}  & 0.5 & 50 \\
			\textbf{Model 4}  & {1e-3} & {128} & 0.6 & 50 \\
			\textbf{Model 5}  & {1e-3} & {128} & 0.5 & 50 \\
			\textbf{Model 6} & {1e-4} & {128} & 0.5 & 50 \\
			\textbf{Model 7}  & {1e-4} & {256} & 0.5 & 50 \\
			\textbf{Model 8}  & {1e-3} & {256} & 0.5 & 50 \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model hyperparameters}
		\label{tab:param1}
	\end{table}

	The other configurations tested, also those that include the modification 
	of other hyperparameters, for example using the Gradient Descent as 
	optimiser, will not be presented in this report due to their 
	barely/insufficient results. Other hyperparameters, such as the loss 
	function and the number of hidden units, are never changed. 
	\newline

	The first experiment performed simply consists in the reduction of the 
	learning rate from $0.001$ down to $0.0001$. 
	
	In Figure \ref{fig:model3-performance} are visualised the performances of 
	the model. The accuracy, which now measures $75.5\%$, increased by $2.2\%$ 
	compared to the previous model. Furthermore, it is clearly visible the 
	different trend of the curve. 
	The same can be said for the loss curve which rapidly decreases towards $0$.
	
	In the Subsection \ref{subsection:epochs} will be discussed a further 
	modification to this model that consist in the increasing the number 
	of epochs.

	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 3}
		\label{fig:model3-performance}
	\end{figure}
	
	In Model 4, the training phase has been carried out using $128$ samples 
	for batch instead of $32$ and the learning rate has been restored to its 
	original value of $0.001$. 
	Furthermore, the dropout value is updated: the probability to keep each 
	neuron is increased to $0.6$. 
		
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/4-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/4-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 4}
		\label{fig:model4-performance}
	\end{figure}

	In this case, the performance has deteriorated: the accuracy is reduced to 
	$69.7\%$ and the loss is increased, although, as can be seen in Figure 
	\ref*{fig:model5-performance}, the trend of the curve remains promising as 
	in the previous model.
	\newline
	
	In Model 5, number or samples for batches and the learning rate are kept 
	equal to the previous experiment, while the dropout has been restored to 
	its original value. 
	The current validation accuracy has begun to rise again, reaching $76.8\%$ 
	and improving the performance of the model 3. However, as it can be seen in 
	Figure \ref{fig:model4-performance}, the curve is growing slower respect to 
	the previous model.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/5-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/5-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 5}
		\label{fig:model5-performance}
	\end{figure}

	As a consequence of the worsening of the performance due to the 
	modification of the dropout, and since the model 3, which has a lower 
	learning rate performs better than the model 2, it was decided to set 
	the learning rate to the previous value of $0.0001$ and restore the dropout 
	to the original value of $0.5$. Instead, the number of examples in the 
	batch for the model 6 has been kept equal to the previous experiments, that 
	is $128$. 
	The curves are shown in Figure \ref{fig:model6-performance}.
		
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/6-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/6-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 6}
		\label{fig:model6-performance}
	\end{figure}

	Unfortunately the results obtained have worsened compared to all the 
	previous performances. This model has a validation accuracy of $64.5\%$, 
	even if the trend of the curve remains promising.
	\newline
	
	The following model, whose performances are shown in Figure 
	\ref{fig:model7-performance}, foresees an increase in the number of 
	examples per batch up to $256$.
	
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/7-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/7-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 7}
		\label{fig:model7-performance}
	\end{figure}
	In this case the validation accuracy, which measures $61.8\%$, is the worst 
	measured so far. In fact, compared to the initial model presented this 
	turns out to be even worse $10.8\%$. 
	\newline
	
	For this reason, it was decided to retrain the model keeping the learning 
	rate value at $0.001$ and the number of examples per batch at $256$.
	As shown in Figure \ref{fig:model8-performance}, the final validation 
	accuracy is $79.4\%$, which is the highest achieved so far.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/8-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/8-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 8}
		\label{fig:model8-performance}
	\end{figure}

	In Table \ref{tab:performace1} are summarised the performance of the 
	presented models. Among the documented model, the best are the model 8, 
	model 5 and model 3. 
	In the following Subsection will be presented the performances of some 
	models after the increase of training epochs.
	
	\begin{table}[H]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cc|cc|c}
			\toprule
			& \multicolumn{2}{c}{\textbf{Accuracy}} & 
			\multicolumn{2}{c}{\textbf{Loss}} & \multirow{2}*{\textbf{Train 
					Time}} \\
			& Train & Validation
			& Train & Validation	& 						 		\\
			\midrule
			\textbf{Model 1} & 98.99\% & 70.30\%  & 0.05 & 4.20 & 406 sec \\
			\textbf{Model 2} & 79.32\% & 80.20\%  & 0.60 & 0.61 & 415 sec \\
			\textbf{Model 3} & 77.70\% & \textbf{80.80\%}  & 0.63 & 0.61 & 445 
			sec \\
			\textbf{Model 4} & 76.75\% & 79.40\%  & 0.65 & 0.61 & 148 sec \\
			\textbf{Model 5} & 84.39\% & \textbf{81.40\%}  & 0.44 & 0.57 & 185 
			sec \\
			\textbf{Model 6} & 71.03\% & 73.50\%  & 0.82 & 0.77 & 149 sec \\
			\textbf{Model 7} & 65.37\% & 68.40\%  & 0.98 & 0.88 & 119 sec \\
			\textbf{Model 8} & 83.60\% & \textbf{80.00\%}  & 0.46 & 0.59 & 120 
			sec \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model performances}
		\label{tab:performace1}
	\end{table}

	\subsection{Increasing the number of epochs}
	\label{subsection:epochs}
	In this Subsection are analysed the performances of the previous models 
	trained for a greater number of epochs. 
	These experiments will not be carried out only on models that have shown 
	better accuracy values, but also on the others since the learning curves 
	were not yet stabilized. The models are trained on GPU which allows 
	training without worsening the time too much.
	
	\begin{table}[htb]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cccc}
			\toprule
			& \textbf{learning rate} & \textbf{batch size} & \textbf{dropout} & 
			\textbf{epochs} \\
			\midrule
			\textbf{Model 3b} & {1e-4} & {32}  & 0.5 & 300 \\
			\textbf{Model 4b}  & {1e-3} & {128} & 0.6 & 300 \\
			\textbf{Model 5b}  & {1e-3} & {128} & 0.5 & 300 \\
			\textbf{Model 6b} & {1e-4} & {128} & 0.5 & 300 \\
			\textbf{Model 7b}  & {1e-4} & {256} & 0.5 & 300 \\
			\textbf{Model 8b}  & {1e-3} & {256} & 0.5 & 300 \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{New model hyperparameters}
		\label{tab:param}
	\end{table}
	
	The first experiment was performed on model 3.
		
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3b-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3b-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 3b}
		\label{fig:model3b-performance}
	\end{figure}

 	In Figure \ref{fig:model3b-performance} are shown the curves. Compared to 
 	the previous, this model has improved the validation accuracy of $9.9\%$, 
	reaching $85.4\%$.
	\newline
	
	The following experiments was carried out on model 4. The results obtained 
	and shown in Figure \ref{fig:model4b-performance} and are worse than those 
	obtained from the previous model.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/4b-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/4b-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 4b}
		\label{fig:model4b-performance}
	\end{figure}
	
	Continuing, the results for the model 5b are shown in Figure 
	\ref{fig:model5b-performance}. Despite the performances of the model on 
	$50$ epochs were among the best, this model obtains lower results compared 
	to model 3b, even if improves the previous ones.
	
	This result was predictable since the learning curve seemed to have already 
	stabilized by training for $50$ epochs.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/5b-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/5b-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 5b}
		\label{fig:model5b-performance}
	\end{figure}
	
	The following model revealed a further increase in performance compared to 
	the previous one and, above all, shows a great difference compared to model 
	trained for $50$ epochs. The current validation accuracy is equal to 
	$82.7\%$. The curves are shown in Figure \ref{fig:model6b-performance}.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/6b-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/6b-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 6b}
		\label{fig:model6b-performance}
	\end{figure}

	The next experiments was carried out on model 7, the presented the worst 
	performances. In this case, training the model for another $250$ increased 
	the accuracy up to $79.4\%$, increasing it by $17.6\%$. Despite this, the 
	model does not present a further improvement to those previously shown.
	The curves are displayed in Figure \ref{fig:model7b-performance}.
	
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/7b-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/7b-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 7b}
		\label{fig:model7b-performance}
	\end{figure}

	The last experiment was performed on model 8, which presented the best 
	performances. In this case, the validation accuracy obtained is more or 
	less the same of the one achieved with only $50$ epochs. 
	
	The situation presented, and shown in Figure \ref{fig:model8b-performance}, 
	is very similar to that which occurred with the model 5. This is because 
	after a certain epoch, both the model have stopped learning.
	
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/8b-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/8b-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 8b}
		\label{fig:model8b-performance}
	\end{figure}

	In Table \ref{tab:performace2} are summarised the performance of the 
	presented models. Among these, the bests are the model 3b, 
	model 6b, model 5b and model 8b. 

	\begin{table}[H]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cc|cc|c}
			\toprule
			& \multicolumn{2}{c}{\textbf{Accuracy}} & 
			\multicolumn{2}{c}{\textbf{Loss}} & \multirow{2}*{\textbf{Train 
					Time}} \\
			& Train & Validation
			& Train & Validation	& 						 		\\
			\midrule
	
			\textbf{Model 3} & 77.70\% & {80.80\%}  & 0.63 & 0.61 & 445 
			sec \\
			\textbf{Model 3b} & 93.47\% & \textbf{85.70\%}  & 0.18 & 0.55 & 
			2974 sec \\
			\textbf{Model 4} & 76.75\% & 79.40\%  & 0.65 & 0.61 & 148 sec \\
			\textbf{Model 4b}  & 84.60\% & \textbf{81.60\%}  & 0.44 & 0.56 & 
			1040 sec \\
			\textbf{Model 5} & 84.39\% & {81.40\%}  & 0.44 & 0.57 & 185 
			sec \\
			\textbf{Model 5b} & 91.91\% & \textbf{81.40\%}  & 0.24 & 0.63 & 893 
			sec \\
			\textbf{Model 6} & 71.03\% & 73.50\%  & 0.82 & 0.77 & 149 sec \\
			\textbf{Model 6b} & 89.86\% & \textbf{84.30\%}  & 0.28 & 0.50 & 896 
			sec \\
			\textbf{Model 7} & 65.37\% & 68.40\%  & 0.98 & 0.88 & 119 sec \\
			\textbf{Model 7b} & 87.08\% & \textbf{84.50\%}  & 0.36 & 0.52 & 707 
			sec \\
			\textbf{Model 8} & 83.60\% & {80.00\%}  & 0.46 & 0.59 & 120 
			sec \\
			\textbf{Model 8b} & 93.40\% & \textbf{84.90\%}  & 0.19 & 0.57 & 714 
			sec \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model performances after increasing the number of 
		epochs}
		\label{tab:performace2}
	\end{table}

	The following subsection will present a further attempt to improve 
	performance, or the addition of batch normalisation to the best models.
	
	\subsection{Batch normalisation}
	\label{subsection:batchnorm}
	
	In this Subsection are analysed the performances of the previous models 
	after the addition of a batch normalisation after the convolutional layers. 
	These experiments has been carried out only on four of the models 
	presented, the ones that have obtained the better performances.
	%{FIXME} why apply batch normalisation? before relu etc... how is it 
	%implemented? cite
	\newline
	
	The first experiment is carried out on model 3, that is the one with the 
	best performances so far. The learning curves, displayed in Figure 
	\ref{fig:model3c-performance}, shown that the accuracy is worst compared to 
	the one of the model without batch normalisation. In fact, the current one 
	is decreased of $3.8\%$, achieving $81.6\%$. %{FIXME: why?}
	
	Despite this, the trend of the curve seems to be still increasing.

	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3c-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3c-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 3c (with batch 
		normalisation)}
		\label{fig:model3c-performance}
	\end{figure}
	
	The next experiment is performed on model 5. In this case, the batch 
	normalisation increases the validation accuracy of the previous model of 
	$4\%$, reaching the new best results of $86.1\%$, as shown in Figure 
	\ref{fig:model5c-performance}.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/5c-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/5c-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 5c (with batch 
			normalisation)}
		\label{fig:model5c-performance}
	\end{figure}
	
	The following experiment has achieved poor result, as for the model 3c. The 
	validation accuracy is decreased down to $80.0\%$, even if the curves is 
	still growing as can be seen in Figure \ref{fig:model6c-performance}. 
	\newline

	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/6c-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/6c-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 6c (with batch 
		normalisation)}
		\label{fig:model6c-performance}
	\end{figure}

	The last experiment performed is able to further increase the validation 
	accuracy of $5.4\%$ respect to the model without batch normalisation, 
	reaching the value of $86.4\%$, that this the best results over all the 
	experiments presented.
	The performances are shown in Figure \ref{fig:model8c-performance}.
	\newline

	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/8c-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/8c-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves on model 8c (with batch 
		normalisation)}
		\label{fig:model8c-performance}
	\end{figure}
	
	The following Table summarise the latest results obtained.
	
	\begin{table}[H]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cc|cc|c}
			\toprule
			& \multicolumn{2}{c}{\textbf{Accuracy}} & 
			\multicolumn{2}{c}{\textbf{Loss}} & \multirow{2}*{\textbf{Train 
					Time}} \\
			& Train & Validation
			& Train & Validation	& 						 		\\
			\midrule
			\textbf{Model 3c} & 87.15\% & {85.50\%}  & 0.37 & 0.46 & 4254 sec \\
			\textbf{Model 5c} & 94.13\% & \textbf{86.70\%}  & 0.17 & 0.52 & 
			1591 sec \\
			\textbf{Model 6c} & 88.27\% & {84.70\%}  & 0.33 & 0.48 & 1616 sec \\
			\textbf{Model 8c} & 94.87\% & {85.10\%}  & 0.14 & 0.57 & 1215 sec \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model performances after the batch normalisation}
		\label{tab:performace3}
	\end{table}

	\section{Test set accuracy} 
	\label{section:finalmodel}
	The test set accuracy was measured on the model 8c. As can be seen in 
	Figure \ref{fig:model8c-test-performance} and summarised in Table 
	\ref{tab:performace-m8c}, also on the test the performances of the model 
	are high. The test accuracy reached $85.03\%$, just $1.1\%$ worst than the 
	validation, and the test loss is $0.50$.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/8c-test-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/8c-test-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Test curves of model 8c}
		\label{fig:model8c-test-performance}
	\end{figure}

	\begin{table}[H]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}ccc|ccc}
			\toprule
			& \multicolumn{3}{c}{\textbf{Accuracy}} & 
			\multicolumn{3}{c}{\textbf{Loss}} \\
			& Train & Validation & Test	& Train & Validation & Test \\
			\midrule
			\textbf{Model 8c} & 55.85\% & {86.40\%} & \textbf{85.03\%} & 1.03 & 
			0.47 & \textbf{0.50} \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Test set performances of the choosen model}
		\label{tab:performace-m8c}
	\end{table}


\end{document}
