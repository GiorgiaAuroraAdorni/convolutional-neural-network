\documentclass[a4paper,12pt]{article} % This defines the style of your paper

\usepackage[top = 2.5cm, bottom = 2.5cm, left = 2.5cm, right = 2.5cm]{geometry} 
\usepackage[utf8]{inputenc} %utf8 % lettere accentate da tastiera
\usepackage[english]{babel} % lingua del documento
\usepackage[T1]{fontenc} % codifica dei font

\usepackage{multirow} % Multirow is for tables with multiple rows within one 
%cell.
\usepackage{booktabs} % For even nicer tables.

\usepackage{graphicx} 

\usepackage{setspace}
\setlength{\parindent}{0in}

\usepackage{float}

\usepackage{fancyhdr}

\usepackage{caption}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{color}

\usepackage[hidelinks]{hyperref}
\usepackage{csquotes}
\usepackage{subfigure}

\newcommand{\footlabel}[2]{%
	\addtocounter{footnote}{1}%
	\footnotetext[\thefootnote]{%
		\addtocounter{footnote}{-1}%
		\refstepcounter{footnote}\label{#1}%
		#2%
	}%
	$^{\ref{#1}}$%
}

\newcommand{\footref}[1]{%
	$^{\ref{#1}}$%
}

\pagestyle{fancy}

\setlength\parindent{24pt}

\fancyhf{}

\lhead{\footnotesize Deep Learning Lab: Assignment 2}

\rhead{\footnotesize Giorgia Adorni}

\cfoot{\footnotesize \thepage} 

\begin{document}
	

	\thispagestyle{empty}  
	\noindent{
	\begin{tabular}{p{15cm}} 
		{\large \bf Deep Learning Lab} \\
		Universit√† della Svizzera Italiana \\ Faculty of Informatics \\ \today  \\
		\hline
		\\
	\end{tabular} 
	
	\vspace*{0.3cm} 
	
	\begin{center}
		{\Large \bf Assignment 2: Convolutional Neural Network}
		\vspace{2mm}
		
		{\bf Giorgia Adorni (giorgia.adorni@usi.ch)}
		
	\end{center}  
}
	\vspace{0.4cm}

	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\section{Introduction}
	The scope of this project is to implement a convolutional neural network to 
	classify the images in the CIFAR-10 dataset.
	
	First of all, the original training set has been shuffled and divided into 
	train and validation sets, with $49000$ and $1000$ images respectively. A 
	seed has been used to reproduce the same sample split and use them in the 
	different models. Instead, the test set provided contains $10000$ images.
	
	A certain preprocessing has been applied to the data. The pixel values of 
	each sample, initially comprised between 0 and 255, have been rescaled 
	between 0 and 1. To represent the class assignments, which were integers 
	between 0 and 9, three binary assignment matrices have been created, one 
	for each set of data. 
	
	The architecture of the convolutional neural network follows the 
	instructions provided, as well as the hyper-parameter values for the models 
	presented in Sections \ref{section:model0} and \ref{section:dropout}.
	In the training phase, mini-es were used. In particular, each 
	epoch splits the training set in different samples of data.
	
	All the models were implemented using \texttt{TensorFlow} and trained on an 
	NVIDIA Tesla V100-PCIE-16GB GPU.
	
	Note: Since mini-batches are used during the training of the models, the 
	loss and the accuracy of all samples are averaged, obtaining a less noisy 
	estimate.
	
	\section{Performance of the initial model}
	\label{section:model0}
	In Table \ref{tab:model0} is summarised the architecture of the network 
	used in the first experiment.	
	
	\begin{figure}[H]
		\centering
		
		\begin{tabular}{cccccccc}
		\toprule
		\textbf{conv1} & \textbf{conv2} & \textbf{mpool1} & \textbf{conv3} &
		\textbf{conv4} & \textbf{mpool1} &   \textbf{fc} &
		\textbf{softmax} \\
		\midrule
		3$\times$3,  32 & 3$\times$3, 32 & 2$\times$2 &3$\times$3, 64 & 
		3$\times$3, 64  & 2$\times$2  & 512 & 10\\
		s. 2$\times$2 &   s. 2$\times$2 &   s. 1$\times$1 & s. 1$\times$1  & s. 
		2$\times$2 & s. 2$\times$2 && \\
		p. same & p. same & p. same  & p. same & p. same & p. same &&\\
		\bottomrule
		\end{tabular}
		\captionof{table}{Network architecture}
		\label{tab:model0}
	\end{figure}
	
	The model is trained for $50$ epochs and \texttt{Adam} is used as 
	optimiser with learning rate $0,001$.
	As loss function, the Softmax Cross Entropy with Logits is used since the 
	model is a multi-class classifier. Moreover, once per epoch, is documented 
	the classification accuracy on both the train and validation set.
	The performance is shown in Figure \ref{fig:model0-performance}.
	
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/1-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/1-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in the initial model}
		\label{fig:model0-performance}
	\end{figure}
	
	As can be seen in Figure (a), the training accuracy rapidly grows up to 
	$100\%$, while the validation accuracy remains stable at $70\%$.  
	The final accuracy on the valid set is $70.30\%$.
	For what concerns the loss, it is clear that the model overfits the data. 
	The training loss is close to $0$ while the validation one 
	diverges.
	
	\begin{table}[H]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cc|cc|c}
			\toprule
			& \multicolumn{2}{c}{\textbf{Accuracy}} & 
			\multicolumn{2}{c}{\textbf{Loss}} & \multirow{2}*{\textbf{Train 
					Time}} \\
			& Train & Validation
			& Train & Validation	& 						 		\\
			\midrule
			\textbf{Model 1} & 98.99\% & 70.30\%  & 0.05 & 4.20 & 406 sec \\
			
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model performances}
		\label{tab:performace-m1}
	\end{table}

	For this reason, in Section \ref{section:dropout} is presented a new model 
	that has the aim of improving these results.
	
	\section{Regularisation of the model with dropout}
	\label{section:dropout}
	The model proposed in this section involve the use of a model 
	regularisation technique, that is the addition of a dropout layer after 
	each max-pooling and fully-connected layer. In particular, during the 
	training phase, the probability to keep each neuron is set to $0.5$, 
	while in the validation set should be $1$.	
	
	The architecture of the new network is presented in Table \ref{tab:model1}.	
	
	\begin{figure}[H]
		\centering
		
		\begin{tabular}{cccccccc}
			\toprule
			\textbf{conv1} & \textbf{conv2} & \textbf{mpool1} & 
			\textbf{conv3} &
			\textbf{conv4} & \textbf{mpool2} &   \textbf{fc} &
			\textbf{softmax} \\
			\midrule
			3$\times$3,  32 & 3$\times$3, 32 & 2$\times$2 &3$\times$3, 64 & 
			3$\times$3, 64  & 2$\times$2  & 512 & 10\\
			s. 2$\times$2 &   s. 2$\times$2 &   s. 1$\times$1 & s. 1$\times$1  
			& s. 
			2$\times$2 & s. 2$\times$2 && \\
			p. same & p. same & p. same  & p. same & p. same & p. same &&\\
			 &  & dropout  &  &  & dropout & dropout & \\
			\bottomrule
		\end{tabular}
		\captionof{table}{Network architecture}
		\label{tab:model1}
	\end{figure}

	The actual performance is shown in Figure \ref{fig:model1-performance}.
	The performances legitimately improved as expected after the application of 
	the dropout. 

	Even if the performance on the training worsen respect to the previous 
	model, since the regularisation is applied only on this set, the 
	performance on the validation increased by $9.90\%$. Now its value is 
	$80.20\%$, significantly better compared to the previous model.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/2-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/2-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in the regularised model}
		\label{fig:model1-performance}
	\end{figure}
	
	Instead, observing the loss curves, after the $30\mathrm{th}$ epochs it is 
	possible to see some signs of overfitting.
	
	\begin{table}[htb]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cc|cc|c}
			\toprule
			& \multicolumn{2}{c}{\textbf{Accuracy}} & 
			\multicolumn{2}{c}{\textbf{Loss}} & \multirow{2}*{\textbf{Train 
					Time}} \\
			& Train & Validation & Train & Validation & \\
			\midrule
			\textbf{Model 2} & 79.32\% & 80.20\%  & 0.60 & 0.61 & 415 sec \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model performances}
		\label{tab:performace-m2}
	\end{table}

	In the following section will be attempted some additional experiments by 
	modifying the model's hyperparameters.
	  
	\section{Hyperparameter settings}
	\label{section:hyperparam}
	
	In this section will be discussed $6$ different additional configurations 
	for the hyperparameters of the network, to improve the validation accuracy. 
	In particular, will be documented the performances according to the 
	modification of the following hyperparameters: learning rate, mini-batch 
	size, dropout and number of epochs. In this analysis, only the models with 
	the best performances will be included. In Table \ref{tab:param1} are 
	documented the different hyperparameter set for the models. 
	
	\begin{table}[htb]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}ccc}
			\toprule
			& \textbf{learning rate} & \textbf{batch size} & \textbf{dropout}  
			\\
			\midrule
			\textbf{Model 1}  & {1e-3} & {32}  &  -  \\
			\textbf{Model 2}  & {1e-3} & {32}  & 0.5 \\
			\textbf{Model 3}  & {1e-4} & {32}  & 0.5 \\
			\textbf{Model 4}  & {1e-3} & {128} & 0.6 \\
			\textbf{Model 5}  & {1e-3} & {128} & 0.5 \\
			\textbf{Model 6}  & {1e-4} & {128} & 0.5 \\
			%\textbf{Model 7}  & {1e-4} & {256} & 0.5 \\
			%\textbf{Model 8}  & {1e-3} & {256} & 0.5 \\
			\textbf{Model 9}  & {1e-3} & {128} & 0.25 - 0.5\\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model hyperparameters}
		\label{tab:param1}
	\end{table}

	All the models are trained for 50 epochs.
	The other configurations tested, also those that include the modification 
	of other hyperparameters, for example using the Gradient Descent as 
	optimiser or adding the decay rate and other parameters to Adam optimizer  
	will not be presented in this report due to their mediocre results.
	\newline

	The first experiment performed simply consists in the reduction of the 
	learning rate from $0.001$ down to $0.0001$. 
	
	In Figure \ref{fig:model3-performance} are visualised the performances of 
	the model. The accuracy, which now measures $80.80\%$, increased only by 
	$0.60\%$ compared to the previous model. Furthermore, it is visible a 
	distance between the training and validation curves. 
	The loss curve rapidly decreases towards $0$, and there are no signs of 
	overfitting.

	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 3}
		\label{fig:model3-performance}
	\end{figure}
		
	In Section \ref{subsection:epochs} will be discussed a further 
	modification to this model that consists of increasing the number of 
	epochs, since the trend of the curve seems to be growing.
	\newline 
	
	In Model 4, the training has been carried out using $128$ samples 
	for batch instead of $32$ and the learning rate has been restored to its 
	original value of $0.001$. 
	Furthermore, the dropout value is updated: the probability to keep each 
	neuron is increased to $0.6$. 
		
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/4-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/4-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 4}
		\label{fig:model4-performance}
	\end{figure}

	In this case, the performance is very similar to the previous experiment, 
	even if slightly worse. The validation accuracy is reduced to 
	$79.4\%$ despite the validation loss is still the same, as can be seen in 
	Figure \ref*{fig:model5-performance}.
	\newline
	
	In Model 5, the number of samples for batches and the learning rate are 
	kept 
	equal to the previous experiment, while the dropout has been restored to 
	its original value. 
	The current validation accuracy has begun to rise again, reaching $81.4\%$ 
	and improving the performance of model 3. However, as it can be seen in 
	Figure \ref{fig:model4-performance}, the validation curve, initially 
	promising, after the $30\mathrm{th}$ epoch it falls below the training 
	curve.

	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/5-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/5-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 5}
		\label{fig:model5-performance}
	\end{figure}

	For the next two experiments, it was decided to set the learning rate to 
	the previous value of $0.0001$ and restore the dropout to his original 
	value of $0.5$. Instead, the number of examples in the batch for model 6 
	has been kept equal to the previous experiments, that is $128$ and increase 
	up to $256$ for model 7. 

	Unfortunately, in both cases, the performance has deteriorated compared to 
	all the previous performances. The first model has a validation accuracy of 
	$73.50\%$, while the second fell to $68.40\%$, that is the worst result
	measured so far.
	\newline
	
	For this reason, it was decided to retrain the model keeping the learning 
	rate value at $0.001$ and the number of examples per batch at $256$.
	As shown in Figure \ref{fig:model8-performance}, the final validation 
	accuracy is $80.00\%$, which is a nice result.
	\newline
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/8-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/8-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 8}
		\label{fig:model8-performance}
	\end{figure}

	In the last experiment, a further attempted modification foresees in the 
	use 
	of different dropouts based on its application after a max-pooling or a 
	fully connected layer. In particular, the rate of the dropout is set to 
	$0.25$ after the max-pooling layers and kept to $0.5$ after the fully 
	connected layer.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/9-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/9-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 9}
		\label{fig:model9-performance}
	\end{figure}
	The performances of the model are shown in Figure 
	\ref{fig:model9-performance}. The validation accuracy obtained, that is 
	$80.5\%$, is among the best three.
	\newline
	
	In Table \ref{tab:performace1} are summarised the performance of the 
	presented models. Among the documented model, the best achieved are model 
	5, model 3 and model 2. 
	In the following section will be presented the performances of some 
	models after the increase of training epochs.
	
	\begin{table}[htb]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cc|cc|c}
			\toprule
			& \multicolumn{2}{c}{\textbf{Accuracy}} & 
			\multicolumn{2}{c}{\textbf{Loss}} & \multirow{2}*{\textbf{Train 
					Time}} \\
			& Train & Validation
			& Train & Validation	& 						 		\\
			\midrule
			\textbf{Model 1} & 98.99\% & 70.30\%  & 0.05 & 4.20 & 406 sec \\
			\textbf{Model 2} & 79.32\% & {80.20\%}  & 0.60 & 0.61 & 415 
			sec \\
			\textbf{Model 3} & 77.70\% & \textbf{80.80\%}  & 0.63 & 0.61 & 445 
			sec \\
			\textbf{Model 4} & 76.75\% & 79.40\%  & 0.65 & 0.61 & 148 sec \\
			\textbf{Model 5} & 84.39\% & \textbf{81.40\%}  & 0.44 & 0.57 & 185 
			sec \\
			\textbf{Model 6} & 71.03\% & 73.50\%  & 0.82 & 0.77 & 149 sec \\
			\textbf{Model 7} & 65.37\% & 68.40\%  & 0.98 & 0.88 & 119 sec \\
			\textbf{Model 8} & 83.60\% & {80.00\%}  & 0.46 & 0.59 & 120 
			sec \\
			\textbf{Model 9} & 93.91\% & \textbf{80.50\%}  & 0.18 & 0.73 & 155 
			sec \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model performances}
		\label{tab:performace1}
	\end{table}
¬†
	\subsection{Modification of the number of hidden units}
	\label{subsection:hidden units}
	
	In this section will be discussed modification to the current best model, 
	which is the model 5, that consists in an increase of the number of 
	hidden units of the fully connected layer from $512$ up to $1024$.
	
	Since the learning curve of the network, shown in the previous section, 
	seems to be underfitting, increasing the complexity of the network should 
	be a good idea. The new performances are shown in Figure 
	\ref{fig:model10-performance}.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/10-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/10-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 10}
		\label{fig:model10-performance}
	\end{figure}
	
	The previous validation accuracy, that was $81.40\%$, increases by 
	$0.90\%$, reaching $82.3\%$.
	
		
	\begin{table}[htb]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cc|cc|c}
			\toprule
			& \multicolumn{2}{c}{\textbf{Accuracy}} & 
			\multicolumn{2}{c}{\textbf{Loss}} & \multirow{2}*{\textbf{Train 
					Time}} \\
			& Train & Validation
			& Train & Validation	& 						 		\\
			\midrule
			\textbf{Model 10} & 87.47\% & \textbf{82.30\%}  & 0.35 & 0.54 & 161 
			sec \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model 10 performances}
		\label{tab:performace10}
	\end{table}
	
	Further modifications to this model will be discussed in Section 
	\ref{subsection:batchnorm}.
	
	\subsection{Increasing the number of epochs}
	\label{subsection:epochs}
	In this section are analysed the performances of the previous models 
	trained for a greater number of epochs. 
	
	These experiments have been carried out only on models 3, 4, 5, 8 and 9 
	since they shown better accuracy values. 
	
	The models are trained on GPU which allows training without worsening the 
	time too much.
	\newline
	
	The first experiment were performed on model 3, which curves are shown in 
	Figure \ref{fig:model3b-performance}. 
		
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3b-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3b-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 3b}
		\label{fig:model3b-performance}
	\end{figure}

 	Compared to the previous, this model has improved the validation accuracy 
 	of $4.9\%$, reaching $85.7\%$, which is the highest result achieved so far.
	\newline
	
	The following experiments was carried out on model 4. 
		
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/4b-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/4b-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 4b}
		\label{fig:model4b-performance}
	\end{figure}

	The results obtained, shown in Figure \ref{fig:model4b-performance}, are 
	worse than those obtained from the previous model. The validation accuracy 
	is fallen to $81.60\%$. In this case, the validation accuracy obtained 
	is more or less the same as the one achieved with only $50$ epochs.
	\newline
	
	Continuing, the results for the model 5b are shown in Figure 
	\ref{fig:model5b-performance}. Despite the performances of the model on 
	$50$ epochs were the best, this model obtains exactly the same results, 
	hence it is no longer the best among the proposed models. 
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/5b-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/5b-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 5b}
		\label{fig:model5b-performance}
	\end{figure}

	In fact, looking at the two curves, it is clearly visible that after few 
	epochs the model stabilizes and stops improving its performance.
	This result was predictable since the learning curve seemed to have already 
	stabilized before $50$ epochs.
	\newline

	The next experiment was carried out on model 8, which presented a further 
	increasing equal to $0.40\%$ of the performance respect to the last 
	experiment.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/8b-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/8b-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 8b}
		\label{fig:model8b-performance}
	\end{figure}

	The situation presented, in particular, the trend of the train and 
	validation accuracy curve, shown in Figure \ref{fig:model8b-performance}, 
	is very similar to the one which occurred with model 5. This is because, 
	after a certain epoch, both the model have stopped or significantly slowed 
	down the learning.
	\newline

	The last experiment was performed on model 9. Despite the performance is 
	better than the latest, it does not reveal a significant increase in 
	performance compared to the latest and, above all, respect to model 3b. 
			
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/9b-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/9b-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 9b}
		\label{fig:model9b-performance}
	\end{figure}
	
	The current validation accuracy is equal to $82.20\%$.
	The curves are displayed in Figure \ref{fig:model9b-performance}.
	\newline

	In Table \ref{tab:performace2} are summarised the performance of the 
	presented models. Among these, the bests are the model 3b, 
	model 8b and model 9b. 

	\begin{table}[H]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cc|cc|c}
			\toprule
			& \multicolumn{2}{c}{\textbf{Accuracy}} & 
			\multicolumn{2}{c}{\textbf{Loss}} & \multirow{2}*{\textbf{Train 
					Time}} \\
			& Train & Validation
			& Train & Validation	& 						 		\\
			\midrule
	
			\textbf{Model 3} & 77.70\% & {80.80\%}  & 0.63 & 0.61 & 445 
			sec \\
			\textbf{Model 3b} & 93.47\% & \textbf{85.70\%}  & 0.18 & 0.55 & 
			2974 sec \\
			\textbf{Model 4} & 76.75\% & 79.40\%  & 0.65 & 0.61 & 148 sec \\
			\textbf{Model 4b}  & 84.60\% & \textbf{81.60\%}  & 0.44 & 0.56 & 
			1040 sec \\
			\textbf{Model 5} & 84.39\% & {81.40\%}  & 0.44 & 0.57 & 185 
			sec \\
			\textbf{Model 5b} & 91.91\% & \textbf{81.40\%}  & 0.24 & 0.63 & 893 
			sec \\
			\textbf{Model 8} & 83.60\% & {80.00\%}  & 0.46 & 0.59 & 120 
			sec \\
			\textbf{Model 8b} & 93.40\% & \textbf{84.90\%}  & 0.19 & 0.57 & 714 
			sec \\
			\textbf{Model 9} & 93.91\% & {80.50\%}  & 0.18 & 0.73 & 155 
			sec \\
			\textbf{Model 9b} & 97.55\% & \textbf{82.20\%}  & 0.08 & 0.96 & 931 
			sec \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model performances after increasing the number of 
		epochs}
		\label{tab:performace2}
	\end{table}

	The following section will present a further attempt to improve 
	performances that consists in the addition of batch normalisation to the 
	best models.
	
	\subsection{Batch normalisation}
	\label{subsection:batchnorm}
	
	In this section are analysed the performances of the models 3c, 5c, 8c, 9c 
	and 10c, after the addition of batch normalisation.
	The main purpose of this change is to improve the performance and the 
	stability of the network. 
	The transform is introduced immediately before each ReLU non-linearity, in 
	order to normalise the layer inputs 
	\footlabel{note1}{Ioffe, S. and Szegedy, C., 2015. Batch normalization: 
	Accelerating deep network training by reducing internal covariate shift. 
	arXiv preprint arXiv:1502.03167.}.
	%\footref{note1}. 
	
	This experiment has been carried out only on five models, which are the 
	ones that have obtained better performances, and for 300 epochs.
	\newline
	
	The first experiment is carried out on model 3b, that is the one with the 
	best performances so far. 
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3c-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3c-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 3c (with batch 
			normalisation)}
		\label{fig:model3c-performance}
	\end{figure}

	The learning curves are displayed in Figure \ref{fig:model3c-performance}. 
	The validation accuracy is slightly worst compared to that of the model 
	without batch normalisation. In fact, the current one is decreased by 
	$0.20\%$.
	\newline
		
	The next experiment is performed on model 5b. In this case, the batch 
	normalisation increases the validation accuracy of the previous model of 
	$5.3\%$, reaching the new best results of $86.5\%$, as shown in Figure 
	\ref{fig:model5c-performance}.

	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/5c-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/5c-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 5c (with batch 
			normalisation)}
		\label{fig:model5c-performance}
	\end{figure}
	
	Probably, the reason why model 5c has better performance than 3c is that 
	batch normalisation works better with a higher learning rate.
	\newline
	
	The experiment performed on model 8c has achieved lower result respect to 
	model 5c even if further increasing the validation accuracy of $0.20\%$ of 
	the model without batch normalisation. 
	The performances are shown in Figure \ref{fig:model8c-performance}.
	\newline

	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/8c-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/8c-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 8c (with batch 
			normalisation)}
		\label{fig:model8c-performance}
	\end{figure}
	
	The model 9c, which performances are shown in Figure 
	\ref{fig:model9c-performance}, performs slightly better compared to the 
	previous model. Moreover, the validation accuracy increases by $3.00\%$ 
	respect to the model without batch normalisation.
		
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/9c-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/9c-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 9c (with batch 
			normalisation)}
		\label{fig:model9c-performance}
	\end{figure}
	
	The last experiment performed has achieved a good result, in particular 
	reaching a validation accuracy of $85.70\%$. Despite these results, the 
	model does not improve the performance of model 5c.
	The performances are shown in Figure \ref{fig:model10c-performance}.
	\newline
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/10c-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/10c-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation curves in model 10c (with batch 
			normalisation)}
		\label{fig:model10c-performance}
	\end{figure}


	The following table summarises the latest results obtained, highlighting 
	model 5c is the best of all the experiments presented.
	
	\begin{table}[H]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cc|cc|c}
			\toprule
			& \multicolumn{2}{c}{\textbf{Accuracy}} & 
			\multicolumn{2}{c}{\textbf{Loss}} & \multirow{2}*{\textbf{Train 
					Time}} \\
			& Train & Validation
			& Train & Validation	& 						 		\\
			\midrule
			\textbf{Model 3c} & 87.15\% & {85.50\%}  & 0.37 & 0.46 & 4254 sec \\
			\textbf{Model 5c} & 94.20\% & \textbf{86.50\%}  & 0.17 & 0.50 & 
			1599 sec \\
			\textbf{Model 8c} & 94.87\% & {85.10\%}  & 0.14 & 0.57 & 1215 sec \\
			\textbf{Model 9c} & 94.74\% & {85.20\%}  & 0.15 & 0.57 & 279 
			sec \\
			\textbf{Model 10c} & 96.67\% & {85.70\%}  & 0.10 & 0.60 & 1768 
			sec \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model performances after the batch normalisation}
		\label{tab:performace3}
	\end{table}

	\section{Test set accuracy} 
	\label{section:finalmodel}
	The test set accuracy was measured on the model 5c, that was the one which 
	presents the best performance. As can be seen in Figure 
	\ref{fig:model5c-test-performance} and summarised in Table 
	\ref{tab:performace-m5c}, also on the test the performances of the model 
	are high. The test accuracy reached $85.36\%$, just $1.14\%$ worse than the 
	validation, and the test loss is $0.50$.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/5c-test-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/5c-test-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Test curves of model 5c}
		\label{fig:model5c-test-performance}
	\end{figure}

	\begin{table}[H]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}ccc|ccc}
			\toprule
			& \multicolumn{3}{c}{\textbf{Accuracy}} & 
			\multicolumn{3}{c}{\textbf{Loss}} \\
			& Train & Validation & Test	& Train & Validation & Test \\
			\midrule
			\textbf{Model 5c} & 94.20\% & {86.50\%} & \textbf{85.36\%} & 1.03 & 
			0.47 & \textbf{0.50} \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Test set performances of the chosen model}
		\label{tab:performace-m5c}
	\end{table}


\end{document}
