\documentclass[a4paper,12pt]{article} % This defines the style of your paper

\usepackage[top = 2.5cm, bottom = 2.5cm, left = 2.5cm, right = 2.5cm]{geometry} 
\usepackage[utf8]{inputenc} %utf8 % lettere accentate da tastiera
\usepackage[english]{babel} % lingua del documento
\usepackage[T1]{fontenc} % codifica dei font

\usepackage{multirow} % Multirow is for tables with multiple rows within one 
%cell.
\usepackage{booktabs} % For even nicer tables.

\usepackage{graphicx} 

\usepackage{setspace}
\setlength{\parindent}{0in}

\usepackage{float}

\usepackage{fancyhdr}

\usepackage{caption}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{color}

\usepackage[hidelinks]{hyperref}
\usepackage{csquotes}
\usepackage{subfigure}

\pagestyle{fancy}

\setlength\parindent{24pt}

\fancyhf{}

\lhead{\footnotesize Deep Learning Lab: Assignment 2}

\rhead{\footnotesize Giorgia Adorni}

\cfoot{\footnotesize \thepage} 

\begin{document}
	

	\thispagestyle{empty}  
	\noindent{
	\begin{tabular}{p{15cm}} 
		{\large \bf Deep Learning Lab} \\
		Universit√† della Svizzera Italiana \\ Faculty of Informatics \\ \today  \\
		\hline
		\\
	\end{tabular} 
	
	\vspace*{0.3cm} 
	
	\begin{center}
		{\Large \bf Assignment 2: Convolutional Neural Network}
		\vspace{2mm}
		
		{\bf Giorgia Adorni (giorgia.adorni@usi.ch)}
		
	\end{center}  
}
	\vspace{0.4cm}

	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\section{Introduction}
	The scope of this project is to implement a convolutional neural network to 
	classify the images in the CIFAR-10 dataset.
	
	First of all, the original training set has been shuffled and divided into 
	train and validation sets, with $49000$ and $1000$ images respectively. A 
	seed has been used to reproduce the same sample split and use them in the 
	different models. Instead, the test set provided contains $10000$ images.
	
	A certain preprocessing has been applied to the data. The pixel values of 
	each sample, initially comprised between 0 and 255, have been rescaled 
	between 0 and 1. To represent the class assignments, which were integers 
	between 0 and 9, three binary assignment matrices have been created, one 
	for each set of data. 
	
	The architecture of the convolutional neural network follow the 
	instructions provided, as well as the hyper-parameter values for the models 
	presented in the Sections \ref{section:model0} and \ref{section:dropout}.
	In the training phase, mini-batches were used. In particular, each 
	epoch splits the training set in different samples of data.
	
	All the models were implemented using \texttt{TensorFlow} and trained on a 
	NVIDIA Tesla V100-PCIE-16GB GPU.
	
	\section{Performance of the initial model}
	\label{section:model0}
	In Table \ref{tab:model0} is summarised the architecture of the network 
	used in the first experiment.	
	
	\begin{figure}[H]
		\centering
		
		\begin{tabular}{cccccccc}
		\toprule
		\textbf{conv1} & \textbf{conv2} & \textbf{mpool1} & \textbf{conv3} &
		\textbf{conv4} & \textbf{mpool1} &   \textbf{fc} &
		\textbf{softmax} \\
		\midrule
		3$\times$3,  32 & 3$\times$3, 32 & 2$\times$2 &3$\times$3, 64 & 
		3$\times$3, 64  & 2$\times$2  & 512 & 10\\
		s. 2$\times$2 &   s. 2$\times$2 &   s. 1$\times$1 & s. 1$\times$1  & s. 
		2$\times$2 & s. 2$\times$2 && \\
		p. same & p. same & p. same  & p. same & p. same & p. same &&\\
		\bottomrule
		\end{tabular}
		\captionof{table}{Network architecture}
		\label{tab:model0}
	\end{figure}
	
	The model is trained for $50$ epochs and \texttt{Adam} is used as 
	optimiser with learning rate $0,001$.
	As loss function, the Softmax Cross Entropy with Logits is used since the 
	model is a multi-class classifier. Moreover, once per epoch, is documented 
	the classification accuracy on both the train and validation set.
	The performance are shown in Figure \ref{fig:model0-performance}.
	
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/1-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/1-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation loss on the initial model}
		\label{fig:model0-performance}
	\end{figure}
	
	As can be seen in Figure (a), the train accuracy rapidly grows up to 
	$1.00$, while the validation accuracy remains stable at $0.70$.  
	The final accuracy on the valid set is $72\%$.
	For what concerns the loss, it is clear that the model overfits the data. 
	In fact, the train loss is next/close to while the validation one diverges.
	
	For this reason, in Section \ref{section:dropout} is presented a new model 
	that has the aim of improving this results.
	
	\section{Regularisation of the model with dropout}
	\label{section:dropout}
	The model proposed in this section involve the use of a model 
	regularisation technique, that is the addition of a dropout layer after 
	each max-pooling and fully-connected layer. In particular, during the 
	training phase, the probability to keep each neuron is setted to $0.5$, 
	while in the validation set should be $1$.	
	
	The architecture of the new network is presented in Table \ref{tab:model1}.	
	
	\begin{figure}[H]
		\centering
		
		\begin{tabular}{cccccccc}
			\toprule
			\textbf{conv1} & \textbf{conv2} & \textbf{mpool1} & 
			\textbf{conv3} &
			\textbf{conv4} & \textbf{mpool2} &   \textbf{fc} &
			\textbf{softmax} \\
			\midrule
			3$\times$3,  32 & 3$\times$3, 32 & 2$\times$2 &3$\times$3, 64 & 
			3$\times$3, 64  & 2$\times$2  & 512 & 10\\
			s. 2$\times$2 &   s. 2$\times$2 &   s. 1$\times$1 & s. 1$\times$1  
			& s. 
			2$\times$2 & s. 2$\times$2 && \\
			p. same & p. same & p. same  & p. same & p. same & p. same &&\\
			 &  & dropout  &  &  & dropout & dropout & dropout\\
			\bottomrule
		\end{tabular}
		\captionof{table}{Network architecture}
		\label{tab:model1}
	\end{figure}
	The actual performance are shown in Figure \ref{fig:model1-performance}.
		
	As can be seen in Figures, the validation performance are legitimately 
	better than the training one, since the regularisation is applied only to 
	the train set and not to the validation.
	
	In this experiment, the validation accuracy is $73.3\%$, a little better 
	respect the previous model.
	Instead, observing the loss curves, with this model there are no signs of 
	overfitting but rather of underfitting. In fact, the training loss is  
	greater than $1.5$ and the validation one is around $1$. Therefore, both 
	have high values. For this reason, in the following section, some 
	experiments will be attempted by modifying the values of the model's 
	hyperparameters.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/2-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/2-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation loss on the regularised model}
		\label{fig:model1-performance}
	\end{figure}
	  
	\section{Hyperparameter settings}
	\label{section:hyperparam}
	
	In this section will be discussed $n$ different configuration for the 
	hyperparameters of the network, with the aim of improving the validation 
	accuracy. In particular, will be documented the performances according to 
	the modification of the following hyperparameters: learning rate, 
	mini-batch size, dropout and number of epochs.
	
	In Table \ref{tab:param} are presented the different hyperparameter 
	settings of the models with the best performances. The other configurations 
	tested, also those that include the modification of other hyperparameters, 
	for example using the Gradient Descent as optimiser, will not be presented 
	in this report due to their barely/insufficient results. Other 
	hyperparameters, such as the loss function and the number of hidden units, 
	are never changed. 
	
	\begin{table}[H]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cccc}
			\toprule
			& \textbf{learning rate} & \textbf{batch size} & \textbf{dropout} & 
			\textbf{epochs} \\
			\midrule
			\textbf{Model 1}  & {1e-3} & {32}  &  -  & 50\\
			\textbf{Model 2}  & {1e-3} & {32}  & 0.5 & 50\\
			\textbf{Model 2b} & {1e-3} & {32}  & 0.5 & 300\\
			\textbf{Model 3}  & {1e-4} & {32}  & 0.5 & 50 \\
			\textbf{Model 3b} & {1e-4} & {32}  & 0.5 & 300 \\
			\textbf{Model 4}  & {1e-3} & {128} & 0.5 & 50 \\
			\textbf{Model 5}  & {1e-3} & {128} & 0.6 & 50 \\
			\textbf{Model 6}  & {1e-4} & {128} & 0.5 & 100 \\
			\textbf{Model 7}  & {1e-4} & {256} & 0.5 & 100 \\
			\textbf{Model 6b} & {1e-4} & {128} & 0.5 & 300 \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model hyperparameters}
		\label{tab:param}
	\end{table}

	The first experiment performed simply consists in training the model for 
	$300$ epochs, instead of $50$, keeping all other hyperparameters the same.
	In Figure \ref{fig:model2b-performance} are shown the curves. Compared to 
	the previous model the performances are more or less the same. 
	This is because after a certain epoch the model has stopped learning.
	
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/2b-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/2b-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation loss on model 2b}
		\label{fig:model2b-performance}
	\end{figure}
	
	In Model 3, the unique change consists in the reduction of the learning 
	rate from $0.001$ down to $0.0001$. 
	
	In Figure \ref{fig:model3-performance} is clearly visible the increase 
	in accuracy and, in particular, the different trend of the curve. The 
	accuracy now is $75.5\%$.
	The same can be said for the loss curve which rapidly decreases towards $0$.
	
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation loss on model 3}
		\label{fig:model3-performance}
	\end{figure}

	A further modification to this model consist of the increasing the number 
	of epochs, since the curves have not yet stabilised. Since the models are 
	trained on GPU, which allows training without worsening the time too much. 
	The resulting performances are shown in Figure 
	\ref{fig:model3b-performance}. The model has improved the validation 
	accuracy of $9.9\%$, reaching $85.4\%$.
	
	\begin{figure}[htb]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3b-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/3b-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation loss on model 3b}
		\label{fig:model3b-performance}
	\end{figure}


	
	In Model 4, the training phase has been carried out using $128$ sample for 
	batch instead of $32$ and the learning rate has been restored to its 
	original value of $0.001$. 
	
	The current validation accuracy is still increasing, in fact now it is 
	$76.8\%$, but, as it can be seen in Figure \ref{fig:model4-performance}, 
	the curve is growing slower respect to the previous model.
	
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/17-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/17-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation loss on model 4}
		\label{fig:model4-performance}
	\end{figure}
	
	In Model 5, the dropout value is updated: the probability to keep each 
	neuron is increased to $0.6$.
	In this case, the performance has deteriorated: the accuracy is decreased 
	to $69.7\%$ and the loss is increased, as can be seen in Figure 
	\ref*{fig:model5-performance}.
	
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/18-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/18-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation loss on model 5}
		\label{fig:model5-performance}
	\end{figure}
	
	As a consequence of the worsening of the performance due to the 
	modification of the learning rate and of the dropout, it was decided to set 
	the learning rate to the previous value fo $0.0001$ and restore the dropout 
	to the original value of $0.5$. Instead, the number of examples in the batch
	has been kept equal to the previous experiments, that is $128$. 
	Furthermore, the number of epochs has been increased to $100$.
	The curves are shown in Figure \ref{fig:model6-performance}.
		
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/32-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/32-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation loss on model 6}
		\label{fig:model6-performance}
	\end{figure}

	This model has a validation accuracy of $76.2\%$, this means that it does 
	not present further increasing with respect to the previous models.
	%FIXME
	The following model, whose performances are shown in Figure 
	\ref{fig:model7-performance}, foresees an increase in the number of 
	examples per batch up to $256$ and has been trained for $100$ epochs.
	
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/35b-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/35b-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation loss on model 7}
		\label{fig:model7-performance}
	\end{figure}
	In this case the validation accuracy, which measures $76.2\%$, got $4.6\%$ 
	worse compared to the last model presented.
	
	For this reason, it was decided to retrain the model 6 for $300$ epochs, in 
	order to compare it with the best current model, or the model 3b.
	
	The validation accuracy for this experiment is $82.7\%$, that is lower than 
	that obtained with the model 3b. The curves are shown in Figure 
	\ref{fig:model7-performance}.
		
	\begin{figure}[H]
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/37-Accuracy.png}
			\caption*{(a)}
		\end{minipage}
		~
		\begin{minipage}[c]{.49\textwidth}
			\centering
			\includegraphics[width=\linewidth]{../src/out/img/37-Loss.png}
			\caption*{(b)}
		\end{minipage}
		\caption{Training and validation loss on model 6b}
		\label{fig:model6b-performance}
	\end{figure}

	In Table \ref{tab:performace} are summarised the performance of the 
	presented models.

	\begin{table}[H]
		\centering
		\begin{tabular}{l@{\hspace{.5cm}}cc|cc|c}
			\toprule
			& \multicolumn{2}{c}{\textbf{Accuracy}} & 
			\multicolumn{2}{c}{\textbf{Loss}} & \multirow{2}*{\textbf{Train 
			Time}} \\
			& Train & Validation
			& Train & Validation	& 						 		\\
			\midrule
			\textbf{Model 1} & 98.96\% & 72.00\%  & 0.05 & 3.79 & 427 sec \\
			\textbf{Model 2} & 44.46\% & 73.30\%  & 1.48 & 0.89 & 427 sec \\
			\textbf{Model 2b} & 45.69\% & 73.20\%  & 1.46 & 0.03 & 3006 sec \\
			\textbf{Model 3} & 46.14\% & 75.50\%  & 1.41 & 0.03 & 435 sec \\
			\textbf{Model 3b} & 54.67\% & \textbf{85.40\%}  & 1.08 & 0.46 & 
			2550 sec \\
			\textbf{Model 4} & 48.65\% & 76.80\%  & 1.32 & 0.74 & 149 sec \\
			\textbf{Model 5} & 36.60\% & 69.70\%  & 1.69 & 1.11 & 148 sec \\
			\textbf{Model 6} & 46.37\% & 76.20\%  & 1.41 & 0.79 & 298 sec \\
			\textbf{Model 7} & 43.65\% & 71.60\%  & 1.50 & 0.92 & 291 sec \\
			\textbf{Model 6b} & 52.23\% & \textbf{82.70\%}  & 1.17 & 0.53 & 904 
			sec \\
			\bottomrule 
		\end{tabular}
		\captionof{table}{Model performances}
		\label{tab:performace}
	\end{table}

	The model 3b is therefore the best among those proposed. As a further 
	attempt to improve performance, batch normalization was added to the model 
	3c.	
	
	\section{compute the test set accuracy and document the result.} 
	\label{section:finalmodel}

\end{document}
